{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime as dt\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Open        High  ...   Adj Close    Volume\n",
      "Date                                ...                      \n",
      "2020-04-01   56.200001   56.471001  ...   55.105000  51970000\n",
      "2020-04-02   55.000000   56.138500  ...   55.851501  56410000\n",
      "...                ...         ...  ...         ...       ...\n",
      "2023-03-30  100.910004  101.160004  ...  100.889999  33086200\n",
      "2023-03-31  101.300003  103.889999  ...  103.730003  36863400\n",
      "\n",
      "[756 rows x 6 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#the start and end date\n",
    "start_date = dt.datetime(2020,4,1)\n",
    "end_date = dt.datetime(2023,4,1)\n",
    "\n",
    "#loading from yahoo finance\n",
    "data = yf.download(\"GOOGL\",start_date, end_date)\n",
    "\n",
    "pd.set_option('display.max_rows', 4)\n",
    "pd.set_option('display.max_columns',5)\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(605, 1) (151, 1)\n"
     ]
    }
   ],
   "source": [
    "# Setting 80 percent data for training\n",
    "training_data_len = math.ceil(len(data) * .8)\n",
    "training_data_len \n",
    "\n",
    "#Splitting the dataset\n",
    "train_data = data[:training_data_len].iloc[:,:1] \n",
    "test_data = data[training_data_len:].iloc[:,:1]\n",
    "print(train_data.shape, test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(605, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting Open Price values\n",
    "dataset_train = train_data.Open.values \n",
    "# Reshaping 1D to 2D array\n",
    "dataset_train = np.reshape(dataset_train, (-1,1)) \n",
    "dataset_train.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.01246754]\n",
      " [0.        ]\n",
      " [0.00764156]\n",
      " [0.01714287]\n",
      " [0.0607844 ]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "# scaling dataset\n",
    "scaled_train = scaler.fit_transform(dataset_train)\n",
    "\n",
    "print(scaled_train[:5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.98362881] [1.] [0.83867656] [0.84481572] [0.86118691]\n"
     ]
    }
   ],
   "source": [
    "# Selecting Open Price values\n",
    "dataset_test = test_data.Open.values \n",
    "# Reshaping 1D to 2D array\n",
    "dataset_test = np.reshape(dataset_test, (-1,1)) \n",
    "# Normalizing values between 0 and 1\n",
    "scaled_test = scaler.fit_transform(dataset_test) \n",
    "print(*scaled_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.01246754, 0.        , 0.00764156, 0.01714287, 0.0607844 ,\n",
      "       0.05355843, 0.06139221, 0.05272728, 0.0727117 , 0.0761091 ,\n",
      "       0.08682596, 0.0943896 , 0.08825454, 0.07413508, 0.0733039 ,\n",
      "       0.08609869, 0.08051948, 0.09974024, 0.09516887, 0.12727273,\n",
      "       0.12018702, 0.11641037, 0.1081195 , 0.12337662, 0.13402599,\n",
      "       0.13574544, 0.14640004, 0.14378702, 0.16011432, 0.14345973,\n",
      "       0.12130912, 0.12896625, 0.13588574, 0.14830132, 0.15021299,\n",
      "       0.16155324, 0.15787013, 0.17764155, 0.16623377, 0.15584416,\n",
      "       0.16645714, 0.16919484, 0.17402597, 0.178026  , 0.17495062,\n",
      "       0.16396881, 0.16949613, 0.17934547, 0.18779741, 0.17715843])]\n",
      "[0.16927791446834417]\n",
      "\n",
      "[array([0.01246754, 0.        , 0.00764156, 0.01714287, 0.0607844 ,\n",
      "       0.05355843, 0.06139221, 0.05272728, 0.0727117 , 0.0761091 ,\n",
      "       0.08682596, 0.0943896 , 0.08825454, 0.07413508, 0.0733039 ,\n",
      "       0.08609869, 0.08051948, 0.09974024, 0.09516887, 0.12727273,\n",
      "       0.12018702, 0.11641037, 0.1081195 , 0.12337662, 0.13402599,\n",
      "       0.13574544, 0.14640004, 0.14378702, 0.16011432, 0.14345973,\n",
      "       0.12130912, 0.12896625, 0.13588574, 0.14830132, 0.15021299,\n",
      "       0.16155324, 0.15787013, 0.17764155, 0.16623377, 0.15584416,\n",
      "       0.16645714, 0.16919484, 0.17402597, 0.178026  , 0.17495062,\n",
      "       0.16396881, 0.16949613, 0.17934547, 0.18779741, 0.17715843]), array([0.        , 0.00764156, 0.01714287, 0.0607844 , 0.05355843,\n",
      "       0.06139221, 0.05272728, 0.0727117 , 0.0761091 , 0.08682596,\n",
      "       0.0943896 , 0.08825454, 0.07413508, 0.0733039 , 0.08609869,\n",
      "       0.08051948, 0.09974024, 0.09516887, 0.12727273, 0.12018702,\n",
      "       0.11641037, 0.1081195 , 0.12337662, 0.13402599, 0.13574544,\n",
      "       0.14640004, 0.14378702, 0.16011432, 0.14345973, 0.12130912,\n",
      "       0.12896625, 0.13588574, 0.14830132, 0.15021299, 0.16155324,\n",
      "       0.15787013, 0.17764155, 0.16623377, 0.15584416, 0.16645714,\n",
      "       0.16919484, 0.17402597, 0.178026  , 0.17495062, 0.16396881,\n",
      "       0.16949613, 0.17934547, 0.18779741, 0.17715843, 0.16927791])]\n",
      "[0.16927791446834417, 0.15038444221793834]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train = []\n",
    "y_train = []\n",
    "for i in range(50, len(scaled_train)):\n",
    "\tX_train.append(scaled_train[i-50:i, 0])\n",
    "\ty_train.append(scaled_train[i, 0])\n",
    "\tif i <= 51:\n",
    "\t\tprint(X_train)\n",
    "\t\tprint(y_train)\n",
    "\t\tprint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "for i in range(50, len(scaled_test)):\n",
    "\tX_test.append(scaled_test[i-50:i, 0])\n",
    "\ty_test.append(scaled_test[i, 0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : (555, 50, 1) y_train : (555, 1)\n"
     ]
    }
   ],
   "source": [
    "# The data is converted to Numpy array\n",
    "X_train, y_train = np.array(X_train), np.array(y_train)\n",
    "\n",
    "#Reshaping\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], X_train.shape[1],1))\n",
    "y_train = np.reshape(y_train, (y_train.shape[0],1))\n",
    "print(\"X_train :\",X_train.shape,\"y_train :\",y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test : (101, 50, 1) y_test : (101, 1)\n"
     ]
    }
   ],
   "source": [
    "# The data is converted to numpy array\n",
    "X_test, y_test = np.array(X_test), np.array(y_test)\n",
    "\n",
    "#Reshaping\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], X_test.shape[1],1))\n",
    "y_test = np.reshape(y_test, (y_test.shape[0],1))\n",
    "print(\"X_test :\",X_test.shape,\"y_test :\",y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GRU, Bidirectional\n",
    "from keras.optimizers import SGD\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wibe/Documents/Skole/UNI_CogSci/8_semester/Data Science/data_science_exam_24/venv_data_science_exam/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n",
      "/Users/wibe/Documents/Skole/UNI_CogSci/8_semester/Data Science/data_science_exam_24/venv_data_science_exam/lib/python3.12/site-packages/keras/src/optimizers/base_optimizer.py:33: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.src.backend' has no attribute 'convert_to_numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 32\u001b[0m\n\u001b[1;32m     25\u001b[0m regressor\u001b[38;5;241m.\u001b[39mcompile(optimizer \u001b[38;5;241m=\u001b[39m SGD(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m,\n\u001b[1;32m     26\u001b[0m \t\t\t\t\t\t\t\tdecay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m, \n\u001b[1;32m     27\u001b[0m \t\t\t\t\t\t\t\tmomentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m, \n\u001b[1;32m     28\u001b[0m \t\t\t\t\t\t\t\tnesterov\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m), \n\u001b[1;32m     29\u001b[0m \t\t\t\tloss \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# fitting the model\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m \u001b[43mregressor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m20\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m regressor\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[0;32m~/Documents/Skole/UNI_CogSci/8_semester/Data Science/data_science_exam_24/venv_data_science_exam/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/Documents/Skole/UNI_CogSci/8_semester/Data Science/data_science_exam_24/venv_data_science_exam/lib/python3.12/site-packages/keras/src/utils/progbar.py:162\u001b[0m, in \u001b[0;36mProgbar.update\u001b[0;34m(self, current, values, finalize)\u001b[0m\n\u001b[1;32m    160\u001b[0m info \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[k], \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m--> 162\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_to_numpy\u001b[49m(\n\u001b[1;32m    163\u001b[0m         backend\u001b[38;5;241m.\u001b[39mnumpy\u001b[38;5;241m.\u001b[39mmean(\n\u001b[1;32m    164\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[k][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[k][\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    165\u001b[0m         )\n\u001b[1;32m    166\u001b[0m     )\n\u001b[1;32m    167\u001b[0m     avg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(avg)\n\u001b[1;32m    168\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(avg) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-3\u001b[39m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.src.backend' has no attribute 'convert_to_numpy'"
     ]
    }
   ],
   "source": [
    "# initializing the RNN\n",
    "regressor = Sequential()\n",
    "\n",
    "# adding RNN layers and dropout regularization\n",
    "regressor.add(SimpleRNN(units = 50, \n",
    "\t\t\t\t\t\tactivation = \"tanh\",\n",
    "\t\t\t\t\t\treturn_sequences = True,\n",
    "\t\t\t\t\t\tinput_shape = (X_train.shape[1],1)))\n",
    "regressor.add(Dropout(0.2))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50, \n",
    "\t\t\t\t\t\tactivation = \"tanh\",\n",
    "\t\t\t\t\t\treturn_sequences = True))\n",
    "\n",
    "regressor.add(SimpleRNN(units = 50,\n",
    "\t\t\t\t\t\tactivation = \"tanh\",\n",
    "\t\t\t\t\t\treturn_sequences = True))\n",
    "\n",
    "regressor.add( SimpleRNN(units = 50))\n",
    "\n",
    "# adding the output layer\n",
    "regressor.add(Dense(units = 1,activation='sigmoid'))\n",
    "\n",
    "# compiling RNN\n",
    "regressor.compile(optimizer = SGD(learning_rate=0.01,\n",
    "\t\t\t\t\t\t\t\tdecay=1e-6, \n",
    "\t\t\t\t\t\t\t\tmomentum=0.9, \n",
    "\t\t\t\t\t\t\t\tnesterov=True), \n",
    "\t\t\t\tloss = \"mean_squared_error\")\n",
    "\n",
    "# fitting the model\n",
    "regressor.fit(X_train, y_train, epochs = 20, batch_size = 2)\n",
    "regressor.summary()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_data_science_exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
