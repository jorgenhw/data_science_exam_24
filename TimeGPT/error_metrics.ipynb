{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_100_test_250_horizon_50_weather_results_weather'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_size = 100 # 1000\n",
    "test_size = 250 # 250\n",
    "horizon = 50 # 50\n",
    "\n",
    "path = os.path.join('results','weather_data',f'train_{train_size}_test_{test_size}_horizon_{horizon}_weather_results.csv')\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "# get name of the file without the .csv\n",
    "name_of_file = os.path.basename(path).split('.')[0]\n",
    "name_of_file = name_of_file + \"_weather\"\n",
    "name_of_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Source       MAE   MAE_std  \\\n",
      "0  train_100_test_250_horizon_50_weather_results_...  1.891755  1.245355   \n",
      "\n",
      "       RMSE  RMSE_std          MAPE      MAPE_std  \n",
      "0  2.246882  1.356945  6.680680e+13  1.302837e+14  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# If you haven't loaded the DataFrame, you can load it using pd.read_csv or other pd functions\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "maes = []\n",
    "rmses = []\n",
    "mapes = []\n",
    "\n",
    "# Group by 'RollingOrigin' and calculate metrics for each group\n",
    "for _, group in df.groupby('RollingOrigin'):\n",
    "    y_true = group['Actual']\n",
    "    y_pred = group['TimeGPT']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "    # Append metrics to lists\n",
    "    maes.append(mae)\n",
    "    rmses.append(rmse)\n",
    "    mapes.append(mape)\n",
    "\n",
    "# Calculate the mean and standard deviation of the metrics\n",
    "mae_mean = np.mean(maes)\n",
    "mae_std = np.std(maes)\n",
    "rmse_mean = np.mean(rmses)\n",
    "rmse_std = np.std(rmses)\n",
    "mape_mean = np.mean(mapes)\n",
    "mape_std = np.std(mapes)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame({\n",
    "    'Source': [name_of_file],\n",
    "    'MAE': [mae_mean],\n",
    "    'MAE_std': [mae_std],\n",
    "    'RMSE': [rmse_mean],\n",
    "    'RMSE_std': [rmse_std],\n",
    "    'MAPE': [mape_mean],\n",
    "    'MAPE_std': [mape_std]\n",
    "})\n",
    "print(results)\n",
    "\n",
    "# save the results\n",
    "results.to_csv(os.path.join('error_metrics',f'{name_of_file}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>TimeGPT</th>\n",
       "      <th>Actual</th>\n",
       "      <th>RollingOrigin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1953-06-01</td>\n",
       "      <td>0.575735</td>\n",
       "      <td>0.343228</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1953-07-01</td>\n",
       "      <td>0.706922</td>\n",
       "      <td>0.357698</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1953-08-01</td>\n",
       "      <td>0.802228</td>\n",
       "      <td>0.185581</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1953-09-01</td>\n",
       "      <td>0.636237</td>\n",
       "      <td>-0.048259</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1953-10-01</td>\n",
       "      <td>0.464142</td>\n",
       "      <td>0.060318</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>1957-02-01</td>\n",
       "      <td>0.137916</td>\n",
       "      <td>-0.137413</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>1957-03-01</td>\n",
       "      <td>0.137567</td>\n",
       "      <td>0.060404</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>1957-04-01</td>\n",
       "      <td>0.142735</td>\n",
       "      <td>0.091391</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1957-05-01</td>\n",
       "      <td>0.143780</td>\n",
       "      <td>0.002730</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>1957-06-01</td>\n",
       "      <td>0.091402</td>\n",
       "      <td>-0.017321</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date   TimeGPT    Actual  RollingOrigin\n",
       "0    1953-06-01  0.575735  0.343228              0\n",
       "1    1953-07-01  0.706922  0.357698              0\n",
       "2    1953-08-01  0.802228  0.185581              0\n",
       "3    1953-09-01  0.636237 -0.048259              0\n",
       "4    1953-10-01  0.464142  0.060318              0\n",
       "..          ...       ...       ...            ...\n",
       "405  1957-02-01  0.137916 -0.137413             40\n",
       "406  1957-03-01  0.137567  0.060404             40\n",
       "407  1957-04-01  0.142735  0.091391             40\n",
       "408  1957-05-01  0.143780  0.002730             40\n",
       "409  1957-06-01  0.091402 -0.017321             40\n",
       "\n",
       "[410 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "train_size = 1000\n",
    "test_size = 50\n",
    "horizon = 10\n",
    "model1 = 'timegpt-1'\n",
    "model2 = 'timegpt-1-long-horizon'\n",
    "\n",
    "path = os.path.join('results','climate_data', f'train_{train_size}_test_{test_size}_horizon_{horizon}_modeltype_{model1}_climate_results.csv')\n",
    "\n",
    "df = pd.read_csv(path)\n",
    "# get name of the file without the .csv\n",
    "name_of_file = os.path.basename(path).split('.')[0]\n",
    "name_of_file\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Source       MAE   MAE_std  \\\n",
      "0  train_1000_test_50_horizon_10_modeltype_timegp...  0.153126  0.064758   \n",
      "\n",
      "       RMSE  RMSE_std     MAPE  MAPE_std  \n",
      "0  0.181398  0.065473  2.12848  1.937849  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# If you haven't loaded the DataFrame, you can load it using pd.read_csv or other pd functions\n",
    "\n",
    "# Initialize lists to store metrics\n",
    "maes = []\n",
    "rmses = []\n",
    "mapes = []\n",
    "\n",
    "# Group by 'RollingOrigin' and calculate metrics for each group\n",
    "for _, group in df.groupby('RollingOrigin'):\n",
    "    y_true = group['Actual']\n",
    "    y_pred = group['TimeGPT']\n",
    "    \n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = mean_absolute_percentage_error(y_true, y_pred)\n",
    "    \n",
    "    # Append metrics to lists\n",
    "    maes.append(mae)\n",
    "    rmses.append(rmse)\n",
    "    mapes.append(mape)\n",
    "\n",
    "# Calculate the mean and standard deviation of the metrics\n",
    "mae_mean = np.mean(maes)\n",
    "mae_std = np.std(maes)\n",
    "rmse_mean = np.mean(rmses)\n",
    "rmse_std = np.std(rmses)\n",
    "mape_mean = np.mean(mapes)\n",
    "mape_std = np.std(mapes)\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "results = pd.DataFrame({\n",
    "    'Source': [name_of_file],\n",
    "    'MAE': [mae_mean],\n",
    "    'MAE_std': [mae_std],\n",
    "    'RMSE': [rmse_mean],\n",
    "    'RMSE_std': [rmse_std],\n",
    "    'MAPE': [mape_mean],\n",
    "    'MAPE_std': [mape_std]\n",
    "})\n",
    "print(results)\n",
    "\n",
    "# save the results\n",
    "results.to_csv(os.path.join('error_metrics',f'{name_of_file}.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all .csv files in error_metrics folder\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "path = 'error_metrics'\n",
    "files = os.listdir(path)\n",
    "files = [file for file in files if file.endswith('.csv')]\n",
    "files\n",
    "\n",
    "# combine all csv files into one\n",
    "combined_csv = pd.concat([pd.read_csv(os.path.join(path, f)) for f in files])\n",
    "combined_csv.to_csv(\"combined_csv.csv\", index=False, encoding='utf-8-sig')\n",
    "combined_csv\n",
    "\n",
    "# save combined results\n",
    "combined_csv.to_csv(os.path.join('error_metrics','combined_error_results.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_data_science_exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
